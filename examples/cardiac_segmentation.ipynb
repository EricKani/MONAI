{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer\n",
    "\n",
    "# assumes the framework is found here, change as necessary\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from monai import application, data, networks, utils\n",
    "import monai.data.augments.augments as augments\n",
    "\n",
    "application.config.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the downsampled segmented images from the Sunnybrook Cardiac Dataset. This is a simple low-res dataset I put together for a workshop. The task is to segment the left ventricle in the image which shows up as an annulus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! [ ! -f scd_lvsegs.npz ] &&  wget -q https://github.com/ericspod/VPHSummerSchool2019/raw/master/scd_lvsegs.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the reader to bring the images in, these are initially in uint16 format with no channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imSrc = data.readers.NPZReader(\"scd_lvsegs.npz\", [\"images\", \"segs\"], other_values=data.streams.OrderType.CHOICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a stream to convert the image format, apply some basic augments using multiple threads, and buffer the stream behind a thread so that batching can be done in parallel with the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeImg(im, seg):\n",
    "    im = utils.arrayutils.rescale_array(im)\n",
    "    im = im[None].astype(np.float32)\n",
    "    seg = seg[None].astype(np.int32)\n",
    "    return im, seg\n",
    "\n",
    "\n",
    "augs = [\n",
    "    normalizeImg,\n",
    "    augments.rot90,\n",
    "    augments.transpose,\n",
    "    augments.flip,\n",
    "    partial(augments.shift, dim_fract=5, order=0, nonzero_index=1),\n",
    "]\n",
    "\n",
    "src = data.augments.augmentstream.ThreadAugmentStream(imSrc, 200, augments=augs)\n",
    "src = data.streams.ThreadBufferStream(src)\n",
    "\n",
    "im, seg = utils.mathutils.first(src)\n",
    "print(im.shape, im.dtype, seg.shape, seg.dtype)\n",
    "plt.imshow(np.hstack([im[0, 0], seg[0, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network, loss, and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "net = networks.nets.UNet(\n",
    "    dimensions=2,\n",
    "    in_channels=1,\n",
    "    num_classes=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ")\n",
    "\n",
    "loss = networks.losses.DiceLoss()\n",
    "opt = torch.optim.Adam(net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train using an Ignite Engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSteps = 100\n",
    "trainEpochs = 20\n",
    "trainSubsteps = 1\n",
    "\n",
    "\n",
    "def _prepare_batch(batch, device=None, non_blocking=False):\n",
    "    x, y = batch\n",
    "    return torch.from_numpy(x).to(device), torch.from_numpy(y).to(device)\n",
    "\n",
    "\n",
    "loss_fn = lambda i, j: loss(i[0], j)\n",
    "\n",
    "trainer = create_supervised_trainer( net, opt, loss_fn, torch.device(\"cuda:0\"), False, _prepare_batch)\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    print(\"Epoch\", engine.state.epoch, \"Loss:\", engine.state.output)\n",
    "\n",
    "\n",
    "fsrc = data.streams.FiniteStream(\n",
    "    src, trainSteps\n",
    ")  # finite stream to train only for as many steps as we specify\n",
    "state = trainer.run(fsrc, trainEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, seg = utils.mathutils.first(imSrc)\n",
    "testim = utils.arrayutils.rescale_array(im[None, None])\n",
    "\n",
    "pred = net.cpu()(torch.from_numpy(testim))\n",
    "\n",
    "pseg = pred[1].data.numpy()\n",
    "\n",
    "plt.imshow(np.hstack([testim[0, 0], pseg[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
