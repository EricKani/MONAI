{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "import logging\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import monai.transforms.compose as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import monai\n",
    "from monai import config\n",
    "from monai.data.nifti_reader import NiftiDataset\n",
    "from monai.transforms import (AddChannel, Rescale, ToTensor, UniformRandomPatch)\n",
    "from monai.handlers.stats_handler import StatsHandler\n",
    "from monai.handlers.mean_dice import MeanDice\n",
    "from monai.visualize import img2tensorboard\n",
    "from monai.data.synthetic import create_test_image_3d\n",
    "from monai.handlers.utils import stopping_fn_from_metric\n",
    "\n",
    "# assumes the framework is found here, change as necessary\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "config.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory and 50 random image, mask paris\n",
    "tempdir = tempfile.mkdtemp()\n",
    "\n",
    "for i in range(50):\n",
    "    im, seg = create_test_image_3d(256, 256, 256)\n",
    "\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, 'im%i.nii.gz' % i))\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, 'seg%i.nii.gz' % i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sorted(glob(os.path.join(tempdir, 'im*.nii.gz')))\n",
    "segs = sorted(glob(os.path.join(tempdir, 'seg*.nii.gz')))\n",
    "\n",
    "# Define transforms for image and segmentation\n",
    "imtrans = transforms.Compose([Rescale(), AddChannel(), UniformRandomPatch((64, 64, 64)), ToTensor()])\n",
    "segtrans = transforms.Compose([AddChannel(), UniformRandomPatch((64, 64, 64)), ToTensor()])\n",
    "\n",
    "# Define nifti dataset, dataloader.\n",
    "ds = NiftiDataset(images, segs, transform=imtrans, seg_transform=segtrans)\n",
    "loader = DataLoader(ds, batch_size=10, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im, seg = monai.utils.misc.first(loader)\n",
    "print(im.shape, seg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "# Create UNet, DiceLoss and Adam optimizer.\n",
    "net = monai.networks.nets.UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    num_classes=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ")\n",
    "\n",
    "loss = monai.losses.DiceLoss(do_sigmoid=True)\n",
    "opt = torch.optim.Adam(net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since network outputs logits and segmentation, we need a custom function.\n",
    "def _loss_fn(i, j):\n",
    "    return loss(i[0], j)\n",
    "\n",
    "# Create trainer\n",
    "device = torch.device(\"cuda:0\")\n",
    "trainer = create_supervised_trainer(net, opt, _loss_fn, device, False,\n",
    "                                    output_transform=lambda x, y, y_pred, loss: [y_pred, loss.item(), y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### optional section for checkpoint and tensorboard logging\n",
    "# adding checkpoint handler to save models (network params and optimizer stats) during training\n",
    "checkpoint_handler = ModelCheckpoint('./', 'net', n_saved=10, require_empty=False)\n",
    "trainer.add_event_handler(event_name=Events.EPOCH_COMPLETED,\n",
    "                          handler=checkpoint_handler,\n",
    "                          to_save={'net': net, 'opt': opt})\n",
    "train_stats_handler = StatsHandler()\n",
    "train_stats_handler.attach(trainer)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    # log loss to tensorboard with second item of engine.state.output, loss.item() from output_transform\n",
    "    writer.add_scalar('Loss/train', engine.state.output[1], engine.state.epoch)\n",
    "\n",
    "    # tensor of ones to use where for converting labels to zero and ones\n",
    "    ones = torch.ones(engine.state.batch[1][0].shape, dtype=torch.int32)\n",
    "    first_output_tensor = engine.state.output[0][1][0].detach().cpu()\n",
    "    # log model output to tensorboard, as three dimensional tensor with no channels dimension\n",
    "    img2tensorboard.add_animated_gif_no_channels(writer, \"first_output_final_batch\", first_output_tensor, 64,\n",
    "                                                 255, engine.state.epoch)\n",
    "    # get label tensor and convert to single class\n",
    "    first_label_tensor = torch.where(engine.state.batch[1][0] > 0, ones, engine.state.batch[1][0])\n",
    "    # log label tensor to tensorboard, there is a channel dimension when getting label from batch\n",
    "    img2tensorboard.add_animated_gif(writer, \"first_label_final_batch\", first_label_tensor, 64,\n",
    "                                     255, engine.state.epoch)\n",
    "    second_output_tensor = engine.state.output[0][1][1].detach().cpu()\n",
    "    img2tensorboard.add_animated_gif_no_channels(writer, \"second_output_final_batch\", second_output_tensor, 64,\n",
    "                                                 255, engine.state.epoch)\n",
    "    second_label_tensor = torch.where(engine.state.batch[1][1] > 0, ones, engine.state.batch[1][1])\n",
    "    img2tensorboard.add_animated_gif(writer, \"second_label_final_batch\", second_label_tensor, 64,\n",
    "                                     255, engine.state.epoch)\n",
    "    third_output_tensor = engine.state.output[0][1][2].detach().cpu()\n",
    "    img2tensorboard.add_animated_gif_no_channels(writer, \"third_output_final_batch\", third_output_tensor, 64,\n",
    "                                                 255, engine.state.epoch)\n",
    "    third_label_tensor = torch.where(engine.state.batch[1][2] > 0, ones, engine.state.batch[1][2])\n",
    "    img2tensorboard.add_animated_gif(writer, \"third_label_final_batch\", third_label_tensor, 64,\n",
    "                                     255, engine.state.epoch)\n",
    "    engine.logger.info(\"Epoch[%s] Loss: %s\", engine.state.epoch, engine.state.output[1])\n",
    "\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### optional section for model validation during training\n",
    "# Define mean dice metric and Evaluator.\n",
    "validation_every_n_epochs = 1\n",
    "\n",
    "# add evaluation metric to the evaluator engine\n",
    "val_metrics = {'Mean Dice': MeanDice(add_sigmoid=True)}\n",
    "evaluator = create_supervised_evaluator(net, val_metrics, device, True,\n",
    "                                        output_transform=lambda x, y, y_pred: (y_pred[0], y))\n",
    "\n",
    "# Add stats event handler to print validation stats via evaluator\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "val_stats_handler = StatsHandler()\n",
    "val_stats_handler.attach(evaluator)\n",
    "\n",
    "# Add early stopping handler to evaluator.\n",
    "early_stopper = EarlyStopping(patience=4,\n",
    "                              score_function=stopping_fn_from_metric('Mean Dice'),\n",
    "                              trainer=trainer)\n",
    "evaluator.add_event_handler(event_name=Events.EPOCH_COMPLETED, handler=early_stopper)\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = NiftiDataset(images[-5:], segs[-5:], transform=imtrans, seg_transform=segtrans)\n",
    "val_loader = DataLoader(ds, batch_size=20, num_workers=8, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=validation_every_n_epochs))\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training data loader\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "train_ds = NiftiDataset(images[:5], segs[:5], transform=imtrans, seg_transform=segtrans)\n",
    "train_loader = DataLoader(train_ds, batch_size=20, num_workers=8, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "train_epochs = 30\n",
    "state = trainer.run(train_loader, train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {tempdir}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
